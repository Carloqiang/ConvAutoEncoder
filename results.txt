gost-sniper@enigma:~$ cd Desktop/ML\ Projects/convAutoencoder/
(venv) gost-sniper@enigma:~/Desktop/ML Projects/convAutoencoder$ python3 main.py
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
init weight
   1    0 / 1004 loss = 0.2532
   1   10 / 1004 loss = 0.0135
   1   20 / 1004 loss = 0.0090
   1   30 / 1004 loss = 0.0035
   1   40 / 1004 loss = 0.0059
   1   50 / 1004 loss = 0.0071
   1   60 / 1004 loss = 0.0098
   1   70 / 1004 loss = 0.0058
   1   80 / 1004 loss = 0.0081
   1   90 / 1004 loss = 0.0030
   1  100 / 1004 loss = 0.0017
   1  110 / 1004 loss = 0.0017
   1  120 / 1004 loss = 0.0028
   1  130 / 1004 loss = 0.0054
   1  140 / 1004 loss = 0.0023
   1  150 / 1004 loss = 0.0022
   1  160 / 1004 loss = 0.0045
   1  170 / 1004 loss = 0.0014
   1  180 / 1004 loss = 0.0027
   1  190 / 1004 loss = 0.0047
   1  200 / 1004 loss = 0.0013
   1  210 / 1004 loss = 0.0049
   1  220 / 1004 loss = 0.0050
   1  230 / 1004 loss = 0.0036
   1  240 / 1004 loss = 0.0031
   1  250 / 1004 loss = 0.0030
   1  260 / 1004 loss = 0.0034
   1  270 / 1004 loss = 0.0024
   1  280 / 1004 loss = 0.0008
   1  290 / 1004 loss = 0.0025
   1  300 / 1004 loss = 0.0032
   1  310 / 1004 loss = 0.0029
   1  320 / 1004 loss = 0.0033
   1  330 / 1004 loss = 0.0038
   1  340 / 1004 loss = 0.0011
   1  350 / 1004 loss = 0.0028
   1  360 / 1004 loss = 0.0065
   1  370 / 1004 loss = 0.0007
   1  380 / 1004 loss = 0.0045
   1  390 / 1004 loss = 0.0004
   1  400 / 1004 loss = 0.0083
   1  410 / 1004 loss = 0.0014
   1  420 / 1004 loss = 0.0022
   1  430 / 1004 loss = 0.0068
   1  440 / 1004 loss = 0.0022
   1  450 / 1004 loss = 0.0022
   1  460 / 1004 loss = 0.0080
   1  470 / 1004 loss = 0.0010
   1  480 / 1004 loss = 0.0027
   1  490 / 1004 loss = 0.0047
   1  500 / 1004 loss = 0.0052
   1  510 / 1004 loss = 0.0022
   1  520 / 1004 loss = 0.0039
   1  530 / 1004 loss = 0.0005
   1  540 / 1004 loss = 0.0022
   1  550 / 1004 loss = 0.0069
   1  560 / 1004 loss = 0.0011
   1  570 / 1004 loss = 0.0024
   1  580 / 1004 loss = 0.0040
   1  590 / 1004 loss = 0.0021
   1  600 / 1004 loss = 0.0081
   1  610 / 1004 loss = 0.0017
   1  620 / 1004 loss = 0.0045
   1  630 / 1004 loss = 0.0040
   1  640 / 1004 loss = 0.0065
   1  650 / 1004 loss = 0.0050
   1  660 / 1004 loss = 0.0061
   1  670 / 1004 loss = 0.0017
   1  680 / 1004 loss = 0.0014
   1  690 / 1004 loss = 0.0023
   1  700 / 1004 loss = 0.0019
   1  710 / 1004 loss = 0.0028
   1  720 / 1004 loss = 0.0014
   1  730 / 1004 loss = 0.0027
   1  740 / 1004 loss = 0.0046
   1  750 / 1004 loss = 0.0020
   1  760 / 1004 loss = 0.0014
   1  770 / 1004 loss = 0.0050
   1  780 / 1004 loss = 0.0019
   1  790 / 1004 loss = 0.0034
   1  800 / 1004 loss = 0.0003
   1  810 / 1004 loss = 0.0032
   1  820 / 1004 loss = 0.0037
   1  830 / 1004 loss = 0.0024
   1  840 / 1004 loss = 0.0034
   1  850 / 1004 loss = 0.0026
   1  860 / 1004 loss = 0.0034
   1  870 / 1004 loss = 0.0022
   1  880 / 1004 loss = 0.0020
   1  890 / 1004 loss = 0.0029
   1  900 / 1004 loss = 0.0032
   1  910 / 1004 loss = 0.0033
   1  920 / 1004 loss = 0.0018
   1  930 / 1004 loss = 0.0015
   1  940 / 1004 loss = 0.0016
   1  950 / 1004 loss = 0.0007
   1  960 / 1004 loss = 0.0011

   1  970 / 1004 loss = 0.0005
   1  980 / 1004 loss = 0.0010
   1  990 / 1004 loss = 0.0025
   1 1000 / 1004 loss = 0.0021

2019-07-21 13:49:04: epoch =    1 , loss = 0.0086 , time = 32660.70 s

