{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trainAutoEncoder.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1yf9rJuXDEI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"1ece02ba-d88e-4ada-b017-f76338ddfa0e","executionInfo":{"status":"ok","timestamp":1563704784211,"user_tz":-60,"elapsed":5400,"user":{"displayName":"YOUSSEF ZYAM","photoUrl":"","userId":"03615834181023021007"}}},"source":["!nvcc --version"],"execution_count":1,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kwi1RxWaDMqK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"635d50ce-9841-4ac8-c190-d677990c798a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nYV66TRSE4Yz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"a80d0b44-e839-4e08-efba-4619bd1efb2f","executionInfo":{"status":"ok","timestamp":1563704974396,"user_tz":-60,"elapsed":1708,"user":{"displayName":"YOUSSEF ZYAM","photoUrl":"","userId":"03615834181023021007"}}},"source":["import sys\n","sys.version"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.6.8 (default, Jan 14 2019, 11:02:34) \\n[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"N3Voke23FFMd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"5442a57f-c2d5-4678-f58f-6223d10a6c6f","executionInfo":{"status":"ok","timestamp":1563705179837,"user_tz":-60,"elapsed":10053,"user":{"displayName":"YOUSSEF ZYAM","photoUrl":"","userId":"03615834181023021007"}}},"source":["!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n","!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n","Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FywKc5RGF1N5","colab_type":"code","colab":{}},"source":["import datetime\n","import glob\n","import os\n","import re\n","\n","import torch\n","import numpy as np\n","from skimage import transform\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","\n","\n","class Rescale(object):\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        normal, blurry = sample['normal'], sample['blurry']\n","\n","        h, w = normal.shape[:2]\n","        if isinstance(self.output_size, int):\n","            if h > w:\n","                new_h, new_w = self.output_size * h / w, self.output_size\n","            else:\n","                new_h, new_w = self.output_size, self.output_size * w / h\n","        else:\n","            new_h, new_w = self.output_size\n","\n","        new_h, new_w = int(new_h), int(new_w)\n","\n","        img = transform.resize(normal, (new_h, new_w))\n","        blurry = transform.resize(blurry, (new_h, new_w))\n","\n","        return {'normal': img, 'blurry': blurry}\n","\n","\n","class RandomCrop(object):\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        if isinstance(output_size, int):\n","            self.output_size = (output_size, output_size)\n","        else:\n","            assert len(output_size) == 2\n","            self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        normal, blurry = sample['normal'], sample['blurry']\n","\n","        h, w = normal.shape[:2]\n","        new_h, new_w = self.output_size\n","\n","        top = np.random.randint(0, h - new_h)\n","        left = np.random.randint(0, w - new_w)\n","\n","        normal = normal[top: top + new_h,\n","                 left: left + new_w]\n","        blurry = blurry[top: top + new_h,\n","                 left: left + new_w]\n","\n","        return {'normal': normal, 'blurry': blurry}\n","\n","\n","class ToTensor(object):\n","    \"\"\"Convert nd-arrays in sample to Tensors.\"\"\"\n","\n","    def __call__(self, sample):\n","        normal, blurry = sample['normal'], sample['blurry']\n","\n","        # swap color axis because\n","        # numpy normal: H x W x C\n","        # torch normal: C X H X W\n","        normal = normal.transpose((2, 0, 1))\n","        return {'normal': torch.from_numpy(normal),\n","                'blurry': torch.from_numpy(blurry)}\n","\n","\n","def findLastCheckpoint(save_dir):\n","    file_list = glob.glob(os.path.join(save_dir, 'model_*.pth'))\n","    if file_list:\n","        epochs_exist = []\n","        for file_ in file_list:\n","            result = re.findall(\".*model_(.*).pth.*\", file_)\n","            epochs_exist.append(int(result[0]))\n","        initial_epoch = max(epochs_exist)\n","    else:\n","        initial_epoch = 0\n","    return initial_epoch\n","\n","\n","def log(*args, **kwargs):\n","    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n","\n","\n","def prepareLoaders(dataset, shuffle_dataset=True, batch_size=4, random_seed=42, validation_split=.85):\n","    dataset_size = len(dataset)\n","    indices = list(range(dataset_size))\n","    split = int(np.floor(validation_split * dataset_size))\n","\n","    if shuffle_dataset:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","    train_indices, val_indices = indices[split:], indices[:split]\n","\n","    # building dataset slicers\n","    train_sampler = SubsetRandomSampler(train_indices)\n","    valid_sampler = SubsetRandomSampler(val_indices)\n","\n","    # building dataset loaders\n","    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                               sampler=train_sampler)\n","    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                                    sampler=valid_sampler)\n","    return train_loader, validation_loader\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOH470jyFRuW","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","from skimage import io, transform\n","import glob\n","import os\n","\n","\n","\n","\n","class imageDataset(Dataset):\n","\n","    def __init__(self, normal_dir, blurry_dir, transform=None):\n","        working_dir = os.path.dirname(os.path.realpath(__file__))\n","\n","        self.path_normal_dir = os.path.join(working_dir, normal_dir)\n","        self.path_blurry_dir = os.path.join(working_dir, blurry_dir)\n","\n","        self.blurry_images = [x.replace(self.path_blurry_dir, '') for x in glob.glob(self.path_blurry_dir + '/*.jpg')]\n","        self.normal_images = [x.replace(self.path_normal_dir, '') for x in glob.glob(self.path_normal_dir + '/*.jpg')]\n","\n","        self.transform = transform\n","\n","        if self.blurry_images not in self.normal_images and len(self.blurry_images) != len(self.normal_images):\n","            raise Exception('mismatch between the normal images and the blurry ones')\n","\n","    def __len__(self):\n","        return len(self.normal_images)\n","\n","    def __getitem__(self, idx):\n","        normal_image = io.imread(self.path_normal_dir + '/' + self.normal_images[idx])\n","        blurry_image = io.imread(self.path_blurry_dir + '/' + self.normal_images[idx])\n","\n","        sample = {'normal': normal_image, 'blurry': blurry_image}\n","\n","        if self.transform:\n","            n, b = self.transform(sample['normal']), self.transform(sample['blurry'])\n","            sample = {'normal': n, 'blurry': b}\n","\n","        return sample\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBHp3MMjFuXT","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","import torch.utils.data\n","import torch.nn.init as init\n","\n","\n","# define the NN architecture\n","class ConvAutoencoder(nn.Module):\n","    def __init__(self, depth=17, n_channels=64, image_channels=3):\n","        super(ConvAutoencoder, self).__init__()\n","        kernel_size = 3\n","        padding = 1\n","        layers = []\n","\n","        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels,\n","                                kernel_size=kernel_size, padding=padding, bias=True)\n","                      )\n","        layers.append(nn.ReLU(inplace=True))\n","        for _ in range(depth-2):\n","            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels,\n","                                    kernel_size=kernel_size, padding=padding, bias=False\n","                                    )\n","                          )\n","            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum=0.95))\n","            layers.append(nn.ReLU(inplace=True))\n","\n","        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels,\n","                                kernel_size=kernel_size, padding=padding, bias=False\n","                                )\n","                      )\n","        self.autoEncoder = nn.Sequential(*layers)\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        y = x\n","        out = self.autoEncoder(x)\n","        return y - out\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                init.orthogonal_(m.weight)\n","                print('init weight')\n","                if m.bias is not None:\n","                    init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                init.constant_(m.weight, 1)\n","                init.constant_(m.bias, 0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CVMr8xYGPG3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"a6775d35-c83e-4766-8cdb-a9a625205a94","executionInfo":{"status":"error","timestamp":1563705353269,"user_tz":-60,"elapsed":1494,"user":{"displayName":"YOUSSEF ZYAM","photoUrl":"","userId":"03615834181023021007"}}},"source":["import argparse\n","import os\n","import time\n","\n","import torch.nn as nn\n","import torch.utils.data\n","from torchvision import transforms\n","\n","\n","\n","parser = argparse.ArgumentParser(description='PyTorch ConAutoEncoder')\n","parser.add_argument('--model', default='ConAutoEncoder', type=str, help='choose a type of model')\n","parser.add_argument('--batch_size', default=2, type=int, help='batch size')\n","parser.add_argument('--normal_data', default='data/normal_images', type=str, help='path of train data')\n","parser.add_argument('--blurry_data', default='data/blurry_images', type=str, help='path of train data')\n","parser.add_argument('--epoch', default=5, type=int, help='number of train epoches')\n","parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n","args = parser.parse_args()\n","\n","data_transform = transforms.Compose([transforms.ToTensor()])\n","dataset = DataSet.imageDataset(args.normal_data, args.blurry_data, transform=data_transform)\n","\n","train_loader, validation_loader = prepareLoaders(dataset, shuffle_dataset=True, batch_size=args.batch_size, )\n","\n","save_dir = os.path.join('models', args.model)\n","\n","if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# initialize the NN\n","model = ConvAutoencoder().to(device)\n","# specify loss function\n","criterion = nn.MSELoss()\n","\n","# specify loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","\n","# number of epochs to train the model\n","n_epochs = args.epoch\n","\n","for epoch in range(1, n_epochs + 1):\n","    # monitor training loss\n","    train_loss = 0.0\n","\n","    start_time = time.time()\n","\n","    # train the model #\n","    for n_count, data in enumerate(train_loader):\n","\n","        normal, blurry = data['normal'].to(device), data['blurry'].to(device)\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(blurry)\n","        # calculate the loss\n","        loss = criterion(outputs, normal)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update running training loss\n","        train_loss += loss.item()\n","        if n_count % 10 == 0:\n","            print('%4d %4d / %4d loss = %2.4f' % (epoch , n_count, len(train_loader), loss.item() / args.batch_size))\n","\n","    elapsed_time = time.time() - start_time\n","    # print avg training statistics\n","    train_loss = train_loss / len(train_loader)\n","    log('epoch = %4d , loss = %4.4f , time = %4.2f s' % (epoch, train_loss, elapsed_time))\n","\n","    torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % epoch))\n","\n","\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [--model MODEL] [--batch_size BATCH_SIZE]\n","                             [--normal_data NORMAL_DATA]\n","                             [--blurry_data BLURRY_DATA] [--epoch EPOCH]\n","                             [--lr LR]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-e974e967-8210-4cb3-a01b-69c87d97918b.json\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iPs8g3uZGJnQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ed2f476e-2d42-479c-a73b-87ad89cf6b9b","executionInfo":{"status":"ok","timestamp":1563705421840,"user_tz":-60,"elapsed":5582,"user":{"displayName":"YOUSSEF ZYAM","photoUrl":"","userId":"03615834181023021007"}}},"source":[""],"execution_count":21,"outputs":[{"output_type":"stream","text":["python3: can't open file 'ipykernel_launcher.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]}]}